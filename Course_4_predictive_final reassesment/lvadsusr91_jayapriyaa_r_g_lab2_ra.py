# -*- coding: utf-8 -*-
"""LVADSUSR91_JAYAPRIYAA_R_G_lab2_ra.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qv4UFpxy-qBCOCNO2GWj4g97cSCJ5jxp
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.cluster import KMeans
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler
from sklearn.model_selection import train_test_split,cross_val_score
from sklearn.metrics import mean_squared_error, accuracy_score, confusion_matrix, recall_score, f1_score, precision_score,silhouette_score, davies_bouldin_score, calinski_harabasz_score,mean_absolute_error, mean_squared_error, r2_score
import warnings
warnings.filterwarnings("ignore")
from sklearn.metrics import classification_report, confusion_matrix

"""Read Data"""

df=pd.read_csv('/content/penguins_classification.csv')
print(df)

"""Data Processing"""

#Handling null values and duplicates
n=df.isnull().sum()
print('Null values in the dataset:\n',n)
dd=df[df.duplicated()]
print('Duplicate rows in the datset:\n',dd)

#Handling outliers
plt.figure(figsize=(20,15))
sns.boxplot(df)
plt.show()

# Define columns for outlier removal
columns_for_outliers = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']
threshold = 3
df_cleaned = df[np.all(np.abs((df[columns_for_outliers] - df[columns_for_outliers].mean()) / df[columns_for_outliers].std()) < threshold, axis=1)]

"""EDA"""

#Describing Data
print('Head of the dataset:\n',df_cleaned.head())
print('Tail of the dataset:\n',df_cleaned.tail())
print('Description of the dataset:\n',df_cleaned.describe())
print('Columns of the dataset:\n',df_cleaned.columns)
print('Shape of the data:\n',df_cleaned.shape)

#visualisation
from matplotlib import pyplot as plt
_df_2['flipper_length_mm'].plot(kind='hist', bins=20, title='flipper_length_mm')
plt.gca().spines[['top', 'right',]].set_visible(False)

from matplotlib import pyplot as plt
_df_5.plot(kind='scatter', x='bill_depth_mm', y='flipper_length_mm', s=32, alpha=.8)
plt.gca().spines[['top', 'right',]].set_visible(False)

from matplotlib import pyplot as plt
import seaborn as sns
def _plot_series(series, series_name, series_index=0):
  palette = list(sns.palettes.mpl_palette('Dark2'))
  xs = series['year']
  ys = series['bill_length_mm']

  plt.plot(xs, ys, label=series_name, color=palette[series_index % len(palette)])

fig, ax = plt.subplots(figsize=(10, 5.2), layout='constrained')
df_sorted = _df_7.sort_values('year', ascending=True)
_plot_series(df_sorted, '')
sns.despine(fig=fig, ax=ax)
plt.xlabel('year')
_ = plt.ylabel('bill_length_mm')
#corelation
corr_matrix = df_cleaned.corr()
sns.heatmap(corr_matrix, annot=True)
plt.title('Correlation Matrix')
plt.show()

"""Model Training"""

#Encoding categorical variables
label_encoder = LabelEncoder()
categorical_columns = ['species', 'island']
for col in categorical_columns:
    df_cleaned[col] = label_encoder.fit_transform(df_cleaned[col])

#Feature and target selection
X = df_cleaned.drop(['species'], axis=1)
y = df_cleaned['species']

# Train test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Feature Scaling
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Model training
rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)
rf_classifier.fit(X_train_scaled, y_train)

"""Model Evaluation"""

# Model Prediction
y_pred = rf_classifier.predict(X_test_scaled)

cvs=cross_val_score(rf_classifier,X_train,y_train,cv=5)

print(classification_report(y_test, y_pred))
print('\nCross validation score:',cvs)
print('\nMean of cross validation score:',cvs.mean())

# Confusion Matrix
conf_matrix = confusion_matrix(y_test, y_pred)
sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='g')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()