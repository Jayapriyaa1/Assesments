# -*- coding: utf-8 -*-
"""LVADSUSR91_JAYAPRIYAA_FA_lab1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RB5RK2ElcGHjzQ85Wd6c1cvtjFOnhxdn
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.cluster import KMeans
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler
from sklearn.model_selection import train_test_split,cross_val_score
from sklearn.metrics import mean_squared_error, accuracy_score, confusion_matrix, recall_score, f1_score, precision_score,silhouette_score, davies_bouldin_score, calinski_harabasz_score,mean_absolute_error, mean_squared_error, r2_score
import warnings
warnings.filterwarnings("ignore")

"""1 Read data"""

df=pd.read_csv('/content/loan_approval (1).csv')
df.head()

"""2- Data Processing"""

#Handling null values and duplicates
null=df.isnull().sum()
print('Null values in the dataset:\n',null)
print('total number of duplicated rows',df.duplicated().sum())


#Handling outliers
plt.figure(figsize=(20,15))
sns.boxplot(df)
plt.show()

q1=df[' residential_assets_value'].quantile(0.25)
q3=df[' residential_assets_value'].quantile(0.75)
iqr=q3-q1
l_limit=q1-(iqr*1.5)
u_limit=q3+(iqr*1.5)
df=df[(df[' residential_assets_value']>l_limit) & (df[' residential_assets_value']<u_limit)]

q1=df[' bank_asset_value'].quantile(0.25)
q3=df[' bank_asset_value'].quantile(0.75)
iqr=q3-q1
l_limit=q1-(iqr*1.5)
u_limit=q3+(iqr*1.5)
df=df[(df[' bank_asset_value']>l_limit) & (df[' bank_asset_value']<u_limit)]

q1=df[' commercial_assets_value'].quantile(0.25)
q3=df[' commercial_assets_value'].quantile(0.75)
iqr=q3-q1
l_limit=q1-(iqr*1.5)
u_limit=q3+(iqr*1.5)
df=df[(df[' commercial_assets_value']>l_limit) & (df[' commercial_assets_value']<u_limit)]
print(df)

"""3 EDA"""

#Data description
print('Head of the dataset:\n',df.head())
print('Information of the dataset:\n',df.info())
print('Description of the dataset:\n',df.describe())

#Visualisation

df.plot(kind='scatter', x=' no_of_dependents', y=' income_annum', s=32, alpha=.8)
plt.gca().spines[['top', 'right',]].set_visible(False)
plt.show()

df[' no_of_dependents'].plot(kind='hist', bins=20, title=' no_of_dependents')
plt.gca().spines[['top', 'right',]].set_visible(False)
plt.show()

df.groupby(' loan_status').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))
plt.gca().spines[['top', 'right',]].set_visible(False)
plt.show()

"""4 Model Training and testing"""

#Encoding categorical variables
lb=LabelEncoder()
df[' education']=lb.fit_transform(df[' education'])
df[' loan_status']=lb.fit_transform(df[' loan_status'])
df[' self_employed']=lb.fit_transform(df[' self_employed'])

#Model development
x=df.drop(columns=[' loan_status','loan_id'])
y=df[' loan_status']
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3)
ml=RandomForestClassifier()
fit=ml.fit(x_train,y_train)
y_pred=ml.predict(x_test)

"""5 Model Evaluation metrics"""

a=accuracy_score(y_test,y_pred)
c=confusion_matrix(y_test,y_pred)
r=recall_score(y_test,y_pred)
f=f1_score(y_test,y_pred)
p=precision_score(y_test,y_pred)
cvs=cross_val_score(ml,x_train,y_train,cv=5)

print('Accuracy Score:',a)
print('\nConfusion Matrix:\n',c)
print('\nRecall Score:',r)
print('\nF1 Score:',f)
print('\nPrecision Score:',p)
print('\nCross validation score:',cvs)
print('\nMean of cross validation score:',cvs.mean())